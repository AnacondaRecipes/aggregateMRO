{% set version = '0.2.1' %}  # [linux or win32]
{% set version = '0.2.1' %}  # [win64]
{% set version = '0.2.1' %}  # [osx]

{% set posix = 'm2-' if win else '' %}
{% set native = 'm2w64-' if win else '' %}

package:
  name: r-tokenizers
  version: {{ version|replace("-", "_") }}

source:
    url:  # [linux or win32]
    - {{ cran_mirror }}/src/contrib/tokenizers_{{ version }}.tar.gz  # [linux or win32]
    - {{ cran_mirror }}/src/contrib/Archive/tokenizers/tokenizers_{{ version }}.tar.gz  # [linux or win32]
  sha256: 28617cdc5ddef5276abfe14a2642999833322b6c34697de1d4e9d6dc7670dd00  # [linux or win32]

  url: https://cran.microsoft.com/snapshot/2018-04-23/bin/windows/contrib/3.5/tokenizers_0.2.1.zip  # [win64]
  sha256: efe13f36119f8e3a6300cac8ee1ced2e820ee59d71a1d5ecddca7baf8873cd2c  # [win64]

  url: https://cran.microsoft.com/snapshot/2018-04-23/bin/macosx/el-capitan/contrib/3.5/tokenizers_0.2.1.tgz  # [osx]
  sha256: 0a398bcd48ab48f3218f55daaa33ce8e5f88d0ff01a015a20ab4a4e163bd9969  # [osx]

build:
  merge_build_host: True  # [win32]
  # If this is a new build for the same version, increment the build number.
  number: 0

  # This is required to make R link correctly on Linux.
  rpaths:
    - lib/R/lib/
    - lib/

# Suggests: covr, knitr, rmarkdown, stopwords (>= 0.9.0), testthat
requirements:
  build:
    - {{ compiler('c') }}        # [linux]
    - {{ compiler('cxx') }}      # [linux]
    - {{native}}toolchain        # [win32]
    - {{posix}}filesystem        # [win32]
    - {{posix}}make              # [linux or win32]
    - {{posix}}sed               # [win32]
    - {{posix}}coreutils         # [win32]
    - {{posix}}zip               # [win32]

  host:
    - mro-base
    - r-rcpp >=0.12.3
    - r-snowballc >=0.5.1
    - r-stringi >=1.0.1

  run:
    - mro-base
    - {{native}}gcc-libs         # [win32]
    - r-rcpp >=0.12.3
    - r-snowballc >=0.5.1
    - r-stringi >=1.0.1

test:
  commands:
    # You can put additional test commands to be run here.
    - $R -e "library('tokenizers')"           # [not win]
    - "\"%R%\" -e \"library('tokenizers')\""  # [win]

  # You can also put a file called run_test.py, run_test.sh, or run_test.bat
  # in the recipe that will be run at test time.

  # requires:
    # Put any additional test requirements here.

about:
  home: https://lincolnmullen.com/software/tokenizers/
  license: MIT + file LICENSE
  summary: 'Convert natural language text into tokens. Includes tokenizers for shingled n-grams,
    skip n-grams, words, word stems, sentences, paragraphs, characters, shingled characters,
    lines, tweets, Penn Treebank, regular expressions, as well as functions for counting
    characters, words, and sentences, and a function for splitting longer texts into
    separate documents, each with the same number of words.  The tokenizers have a consistent
    interface, and the package is built on the ''stringi'' and ''Rcpp'' packages for  fast
    yet correct tokenization in ''UTF-8''. '

  license_family: MIT

extra:
  recipe-maintainers:
    - mingwandroid

# The original CRAN metadata for this package was:

# Package: tokenizers
# Type: Package
# Title: Fast, Consistent Tokenization of Natural Language Text
# Version: 0.2.1
# Date: 2018-03-29
# Description: Convert natural language text into tokens. Includes tokenizers for shingled n-grams, skip n-grams, words, word stems, sentences, paragraphs, characters, shingled characters, lines, tweets, Penn Treebank, regular expressions, as well as functions for counting characters, words, and sentences, and a function for splitting longer texts into separate documents, each with the same number of words.  The tokenizers have a consistent interface, and the package is built on the 'stringi' and 'Rcpp' packages for  fast yet correct tokenization in 'UTF-8'.
# License: MIT + file LICENSE
# LazyData: yes
# Authors@R: c(person("Lincoln", "Mullen", role = c("aut", "cre"), email = "lincoln@lincolnmullen.com", comment = c(ORCID = "0000-0001-5103-6917")), person("Os", "Keyes", role = c("ctb"), email = "ironholds@gmail.com", comment = c(ORCID = "0000-0001-5196-609X")), person("Dmitriy", "Selivanov", role = c("ctb"), email = "selivanov.dmitriy@gmail.com"), person("Jeffrey", "Arnold", role = c("ctb"), email = "jeffrey.arnold@gmail.com", comment = c(ORCID = "0000-0001-9953-3904")), person("Kenneth", "Benoit", role = c("ctb"), email = "kbenoit@lse.ac.uk", comment = c(ORCID = "0000-0002-0797-564X")))
# URL: https://lincolnmullen.com/software/tokenizers/
# BugReports: https://github.com/ropensci/tokenizers/issues
# RoxygenNote: 6.0.1
# Depends: R (>= 3.1.3)
# Imports: stringi (>= 1.0.1), Rcpp (>= 0.12.3), SnowballC (>= 0.5.1)
# LinkingTo: Rcpp
# Suggests: covr, knitr, rmarkdown, stopwords (>= 0.9.0), testthat
# VignetteBuilder: knitr
# NeedsCompilation: yes
# Packaged: 2018-03-29 17:26:00 UTC; lmullen
# Author: Lincoln Mullen [aut, cre] (<https://orcid.org/0000-0001-5103-6917>), Os Keyes [ctb] (<https://orcid.org/0000-0001-5196-609X>), Dmitriy Selivanov [ctb], Jeffrey Arnold [ctb] (<https://orcid.org/0000-0001-9953-3904>), Kenneth Benoit [ctb] (<https://orcid.org/0000-0002-0797-564X>)
# Maintainer: Lincoln Mullen <lincoln@lincolnmullen.com>
# Repository: CRAN
# Date/Publication: 2018-03-29 20:07:40 UTC

# See
# http://docs.continuum.io/conda/build.html for
# more information about meta.yaml
