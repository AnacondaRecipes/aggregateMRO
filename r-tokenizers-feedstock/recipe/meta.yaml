{% set version = '0.1.4' %}

{% set posix = 'm2-' if win else '' %}
{% set native = 'm2w64-' if win else '' %}

package:
  name: r-tokenizers
  version: {{ version|replace("-", "_") }}

source:
  fn: tokenizers_0.1.4.tar.gz  # [linux or win32]
  url:  # [linux or win32]
    - {{ cran_mirror }}/src/contrib/tokenizers_0.1.4.tar.gz  # [linux or win32]
    - {{ cran_mirror }}/src/contrib/Archive/tokenizers/tokenizers_0.1.4.tar.gz  # [linux or win32]
  sha256: 693e19e32605f4c66a51b1eb84258a973ac2fe1d2f919b28e66944721aab9ae1  # [linux or win32]




  url:  {{ cran_mirror }}/bin/windows/contrib/3.4/tokenizers_0.1.4.zip  # [win64]
  sha256: 68eef257d92f6dc830dd4f14a275ef5c98923a22e356117aba351b97b2479eb5  # [win64]

  url:  {{ cran_mirror }}/bin/macosx/el-capitan/contrib/3.4/tokenizers_0.1.4.tgz  # [osx]
  sha256: 071a11abf7929ee0e4822ea2bd678437685cda3647eb0a2a9ca8feb1218f6a88  # [osx]


build:
  merge_build_host: True  # [linux or win32]
  # If this is a new build for the same version, increment the build number.
  number: 0


  # This is required to make R link correctly on Linux.
  rpaths:
    - lib/R/lib/
    - lib/

# Suggests: testthat, covr, knitr, rmarkdown
requirements:
  build:
    - {{ compiler('c') }}          # [linux]
    - {{ compiler('cxx') }}        # [linux]
    - {{native}}toolchain          # [win32]
    - {{posix}}filesystem          # [win32]
    - {{posix}}make                # [linux or win32]

  host:
    - mro-base
    - r-rcpp >=0.12.3
    - r-snowballc >=0.5.1
    - r-stringi >=1.0.1

  run:
    - mro-base
    - {{native}}gcc-libs           # [win32]
    - r-rcpp >=0.12.3
    - r-snowballc >=0.5.1
    - r-stringi >=1.0.1

test:
  commands:
    # You can put additional test commands to be run here.
    - $R -e "library('tokenizers')"           # [not win]
    - "\"%R%\" -e \"library('tokenizers')\""  # [win]

  # You can also put a file called run_test.py, run_test.sh, or run_test.bat
  # in the recipe that will be run at test time.

  # requires:
    # Put any additional test requirements here.

about:
  home: https://github.com/ropensci/tokenizers
  license: MIT + file LICENSE
  summary: Convert natural language text into tokens. The tokenizers have a consistent interface
    and are compatible with Unicode, thanks to being built on the 'stringi' package.
    Includes tokenizers for shingled n-grams, skip n-grams, words, word stems, sentences,
    paragraphs, characters, lines, and regular expressions.
  license_family: MIT

extra:
  recipe-maintainers:
    - mingwandroid

# The original CRAN metadata for this package was:

# Package: tokenizers
# Type: Package
# Title: A Consistent Interface to Tokenize Natural Language Text
# Version: 0.1.4
# Description: Convert natural language text into tokens. The tokenizers have a consistent interface and are compatible with Unicode, thanks to being built on the 'stringi' package. Includes tokenizers for shingled n-grams, skip n-grams, words, word stems, sentences, paragraphs, characters, lines, and regular expressions.
# License: MIT + file LICENSE
# LazyData: yes
# Authors@R: c(person("Lincoln", "Mullen", role = c("aut", "cre"), email = "lincoln@lincolnmullen.com"), person("Dmitriy", "Selivanov", role = c("ctb"), email = "selivanov.dmitriy@gmail.com"))
# URL: https://github.com/ropensci/tokenizers
# BugReports: https://github.com/ropensci/tokenizers/issues
# RoxygenNote: 5.0.1
# Depends: R (>= 3.1.3)
# Imports: stringi (>= 1.0.1), Rcpp (>= 0.12.3), SnowballC (>= 0.5.1)
# LinkingTo: Rcpp
# Suggests: testthat, covr, knitr, rmarkdown
# VignetteBuilder: knitr
# NeedsCompilation: yes
# Packaged: 2016-08-29 19:15:04 UTC; lmullen
# Author: Lincoln Mullen [aut, cre], Dmitriy Selivanov [ctb]
# Maintainer: Lincoln Mullen <lincoln@lincolnmullen.com>
# Repository: CRAN
# Date/Publication: 2016-08-29 22:59:29

# See
# http://docs.continuum.io/conda/build.html for
# more information about meta.yaml
